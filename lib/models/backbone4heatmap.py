import torch
import torch.nn as nn
import numpy as np

from lib.backbones.dla import dla34
from lib.backbones.dlaup import DLAUp
from lib.helpers.decode_helper import _topk, _nms

class Extractor(nn.Module):
    def __init__(self, backbone='dla34', neck='DLAUp', downsample=4, mean_size=None, model_type='DID'):
        super(Extractor, self).__init__()
        self.backbone = self.backbone = globals()[backbone](pretrained=False, return_levels=True)
        self.mean_size = nn.Parameter(torch.tensor(mean_size, dtype=torch.float32), requires_grad=False)
        channels = self.backbone.channels

        self.first_level = int(np.log2(downsample))  # if downsample=4, np.log2(downsample)=2, first_level=2
        scales = [2 ** i for i in range(len(channels[self.first_level:]))]
        self.feat_up = globals()[neck](channels[self.first_level:], scales_list=scales)

        scales = [2 ** i for i in range(len(channels[2:]))]
        self.feat_up = DLAUp(in_channels_list=channels[2:], scales_list=scales)

    def forward(self, x):
        feat_backbone = self.backbone(x)
        fusion_features = self.feat_up(feat_backbone[2:])
        # return fusion_features[-1].flatten(start_dim=2).mean(dim=1)
        return fusion_features[-1]

class DID(nn.Module):
    def __init__(self, backbone='dla34', neck='DLAUp', downsample=4, mean_size=None, model_type='DID'):
        assert downsample in [4, 8, 16, 32]
        super().__init__()

        self.model_type = model_type
        self.backbone = globals()[backbone](pretrained=True, return_levels=True)
        self.head_conv = 256  # default setting for head conv
        self.mean_size = nn.Parameter(torch.tensor(mean_size, dtype=torch.float32), requires_grad=False)
        self.cls_num = mean_size.shape[0]
        channels = self.backbone.channels  # channels list for feature maps generated by backbone

        self.first_level = int(np.log2(downsample))  # if downsample=4, np.log2(downsample)=2, first_level=2
        scales = [2 ** i for i in range(len(channels[self.first_level:]))]
        self.feat_up = globals()[neck](channels[self.first_level:], scales_list=scales)

        # initialize the head of pipeline, according to heads setting.
        self.heatmap = nn.Sequential(
            nn.Conv2d(channels[self.first_level], self.head_conv, kernel_size=3, padding=1, bias=True),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.head_conv, 3, kernel_size=1, stride=1, padding=0, bias=True))
        self.offset_2d = nn.Sequential(
            nn.Conv2d(channels[self.first_level], self.head_conv, kernel_size=3, padding=1, bias=True),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.head_conv, 2, kernel_size=1, stride=1, padding=0, bias=True))
        self.size_2d = nn.Sequential(
            nn.Conv2d(channels[self.first_level], self.head_conv, kernel_size=3, padding=1, bias=True),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.head_conv, 2, kernel_size=1, stride=1, padding=0, bias=True))

        self.offset_3d = nn.Sequential(
            nn.Conv2d(channels[self.first_level] + 2 + self.cls_num, self.head_conv, kernel_size=3, padding=1,
                      bias=True),
            nn.BatchNorm2d(self.head_conv),
            nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(self.head_conv, 2, kernel_size=1, stride=1, padding=0, bias=True))
        self.size_3d = nn.Sequential(
            nn.Conv2d(channels[self.first_level] + 2 + self.cls_num, self.head_conv, kernel_size=3, padding=1,
                      bias=True),
            nn.BatchNorm2d(self.head_conv),
            nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(self.head_conv, 3, kernel_size=1, stride=1, padding=0, bias=True))
        self.heading = nn.Sequential(
            nn.Conv2d(channels[self.first_level] + 2 + self.cls_num, self.head_conv, kernel_size=3, padding=1,
                      bias=True),
            nn.BatchNorm2d(self.head_conv),
            nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(self.head_conv, 24, kernel_size=1, stride=1, padding=0, bias=True))

        self.vis_depth = nn.Sequential(
            nn.Conv2d(channels[self.first_level] + 2 + self.cls_num, self.head_conv, kernel_size=3, padding=1,
                      bias=True),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(self.head_conv, 1, kernel_size=1, stride=1, padding=0, bias=True))
        self.att_depth = nn.Sequential(
            nn.Conv2d(channels[self.first_level] + 2 + self.cls_num, self.head_conv, kernel_size=3, padding=1,
                      bias=True),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(self.head_conv, 1, kernel_size=1, stride=1, padding=0, bias=True))
        self.vis_depth_uncer = nn.Sequential(
            nn.Conv2d(channels[self.first_level] + 2 + self.cls_num, self.head_conv, kernel_size=3, padding=1,
                      bias=True),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(self.head_conv, 1, kernel_size=1, stride=1, padding=0, bias=True))
        self.att_depth_uncer = nn.Sequential(
            nn.Conv2d(channels[self.first_level] + 2 + self.cls_num, self.head_conv, kernel_size=3, padding=1,
                      bias=True),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(self.head_conv, 1, kernel_size=1, stride=1, padding=0, bias=True))

        # init layers
        self.heatmap[-1].bias.data.fill_(-2.19)
        self.fill_fc_weights(self.offset_2d)
        self.fill_fc_weights(self.size_2d)

    def forward(self, input):
        device_id = input.device
        feat_backbone = self.backbone(input)
        fusion_features = self.feat_up(feat_backbone[self.first_level:])
        feat = fusion_features[-1]
        ret = {}
        '''
        ret = {}
        for head in self.heads:
            ret[head] = self.__getattr__(head)(feat)
        '''
        ret['heatmap'] = self.heatmap(feat)
        ret['offset_2d'] = self.offset_2d(feat)
        ret['size_2d'] = self.size_2d(feat)

        return feat

    def fill_fc_weights(self, layers):
        for m in layers.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.normal_(m.weight, std=0.001)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)


if __name__ == '__main__':
    input = torch.randn(1, 3, 352, 1120)
    levels = [1, 1, 1, 3, 4, 1]
    channels = [16, 32, 128, 256, 512, 1024]
    mean_size = torch.randn(3, 2)
    # m = Extractor(mean_size=mean_size)
    m = DID(mean_size=mean_size)
    out = m(input)
    for item in out:
        if isinstance(item, list):
            for x in item:
                print(f'x shape: {x.shape}')
        else:
            print(f'item shape: {item.shape}')


